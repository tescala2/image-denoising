{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b66868f590f415daa066e0db979f6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7675a9eda3b749bea9e3271fc6ac86cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aedd46dd73f24c0c8423880030a15fc0",
              "IPY_MODEL_724ac8e851174860998e01dd68cc1ac0"
            ]
          }
        },
        "7675a9eda3b749bea9e3271fc6ac86cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aedd46dd73f24c0c8423880030a15fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b3eecc5b3ef4997a9d37cb2beda4016",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67e9295208df4876b1bd8780074f1cb3"
          }
        },
        "724ac8e851174860998e01dd68cc1ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_736fb9519bb94bcc9b465c58ea946c5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1999642624/? [01:04&lt;00:00, 69860842.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba446ed6c847429bb7199b11b50ce411"
          }
        },
        "2b3eecc5b3ef4997a9d37cb2beda4016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67e9295208df4876b1bd8780074f1cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "736fb9519bb94bcc9b465c58ea946c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba446ed6c847429bb7199b11b50ce411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Qn8iyQvu28"
      },
      "source": [
        "'''\r\n",
        "Names (Please write names in <Last Name, First Name> format):\r\n",
        "1. Doe, John\r\n",
        "2. Doe, Jane\r\n",
        "\r\n",
        "TODO: Semantic segmentation\r\n",
        "\r\n",
        "TODO: Report what each member did in this project\r\n",
        "\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnVoR1U3Y5_T",
        "outputId": "5a39a9f2-9f4a-4238-a152-16fdaf181308"
      },
      "source": [
        "# Mound google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KqnPNXav6tY"
      },
      "source": [
        "import argparse\r\n",
        "import torch, torchvision\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sklearn\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYhG6LjYv_iv"
      },
      "source": [
        "# Commandline arguments\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument('--train_network',\r\n",
        "    action='store_true', help='If set, then trains network')\r\n",
        "parser.add_argument('--batch_size',\r\n",
        "    type=int, default=4, help='Number of samples per batch')\r\n",
        "parser.add_argument('--n_epoch',\r\n",
        "    type=int, default=1, help='Number of times to iterate through dataset')\r\n",
        "parser.add_argument('--learning_rate',\r\n",
        "    type=float, default=1e-8, help='Base learning rate (alpha)')\r\n",
        "parser.add_argument('--learning_rate_decay',\r\n",
        "    type=float, default=0.50, help='Decay rate for learning rate')\r\n",
        "parser.add_argument('--learning_rate_decay_period',\r\n",
        "    type=float, default=1, help='Period before decaying learning rate')\r\n",
        "parser.add_argument('--momentum',\r\n",
        "    type=float, default=0.90, help='Momentum discount rate (beta)')\r\n",
        "parser.add_argument('--lambda_weight_decay',\r\n",
        "    type=float, default=0.0, help='Lambda used for weight decay')\r\n",
        "\r\n",
        "# TODO: please add additional necessary commandline arguments here\r\n",
        "parser.add_argument('-f')\r\n",
        "\r\n",
        "\r\n",
        "args = parser.parse_args()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mIYdb4SWtBr"
      },
      "source": [
        "# Set hyper parameters in notebook\r\n",
        "train_network = True #True or False\r\n",
        "batch_size = 8\r\n",
        "n_epoch = 2\r\n",
        "learning_rate = 1e-1\r\n",
        "learning_rate_decay = 0.8\r\n",
        "learning_rate_decay_period = 10\r\n",
        "momentum = 0.5\r\n",
        "lambda_weight_decay = 0.5"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYW-TCBywFT8"
      },
      "source": [
        "class FullyConvolutionalNetwork(torch.nn.Module):\r\n",
        "    '''\r\n",
        "    Fully convolutional network\r\n",
        "\r\n",
        "    Args:\r\n",
        "        Please add any necessary arguments\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(FullyConvolutionalNetwork, self).__init__()\r\n",
        "\r\n",
        "        # TODO: Design your neural network using\r\n",
        "        # (1) convolutional layers\r\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\r\n",
        "        # (2) max pool layers\r\n",
        "        # https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.max_pool2d\r\n",
        "        # (3) average pool layers\r\n",
        "        # https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.avg_pool2d\r\n",
        "        # (4) transposed convolutional layers\r\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html\r\n",
        "\r\n",
        "\r\n",
        "        # block 1 - 3x640x480 to 64x320x240\r\n",
        "        self.conv1a = nn.Conv2d(3, 64, kernel_size = 3, padding = 1)\r\n",
        "        self.conv1b = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\r\n",
        "        self.down1 = nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        # block 2 - 64x320x240 to 128x160x120\\n\",\r\n",
        "        self.conv2a = nn.Conv2d(64, 128, kernel_size = 3, padding = 1)\r\n",
        "        self.conv2b = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\r\n",
        "        self.down2 = nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        # block 3 - 128x160x120 to 256x80x60\\n\",\r\n",
        "        self.conv3a = nn.Conv2d(128, 256, kernel_size = 3, padding = 1)\r\n",
        "        self.conv3b = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\r\n",
        "        self.down3 = nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        # block 4 - 256x80x60 to 512x40x30\\n\",\r\n",
        "        self.conv4a = nn.Conv2d(256, 512, kernel_size = 3, padding = 1)\r\n",
        "        self.conv4b = nn.Conv2d(512, 512, kernel_size = 3, padding = 1)\r\n",
        "        self.down4 = nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        # block 5 - 512x40x30 to 1024x20x15\\n\",\r\n",
        "        self.conv5a = nn.Conv2d(512, 1024, kernel_size = 3, padding = 1)\r\n",
        "        self.conv5b = nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1)\r\n",
        "        self.down5 = nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        # block 6 - 1024x20x15 to 512x40x30\\n\",\r\n",
        "        self.conv6a = nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1)\r\n",
        "        self.conv6b = nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1)\r\n",
        "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size = 3, padding = 1)\r\n",
        "\r\n",
        "        # block 7 - 512x40x30 to 256x80x60\\n\",\r\n",
        "        self.conv7a = nn.Conv2d(512, 512, kernel_size = 3, padding = 1)\r\n",
        "        self.conv7b = nn.Conv2d(512, 512, kernel_size = 3, padding = 1)\r\n",
        "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size = 3, padding = 1)\r\n",
        "\r\n",
        "        # block 8 - 256x80x60 to 128x160x120\\n\",\r\n",
        "        self.conv8a = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\r\n",
        "        self.conv8b = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\r\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size = 3, padding = 1)\r\n",
        "\r\n",
        "        # block 9 - 128x160x120 to 64x320x240\\n\",\r\n",
        "        self.conv9a = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\r\n",
        "        self.conv9b = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\r\n",
        "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size = 3, padding = 1)\r\n",
        "\r\n",
        "        # block 10 - 64x320x240 to 3x640x480\\n\",\r\n",
        "        self.conv10a = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\r\n",
        "        self.conv10b = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\r\n",
        "        self.up5 = nn.ConvTranspose2d(64, 3, kernel_size = 3, padding = 1)\r\n",
        "\r\n",
        "        self.conv11a = nn.Conv2d(3, 3, kernel_size = 3, padding = 1)\r\n",
        "        self.conv11b = nn.Conv2d(3, 3, kernel_size = 3, padding = 1)\r\n",
        "        self.conv11c = nn.Conv2d(3, 1, kernel_size = 1, padding = 0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        '''\r\n",
        "            Args:\r\n",
        "                x : torch.Tensor\r\n",
        "                    tensor of N x d\r\n",
        "\r\n",
        "            Returns:\r\n",
        "                torch.Tensor\r\n",
        "                    tensor of n_output\r\n",
        "        '''\r\n",
        "\r\n",
        "        # TODO: Implement forward function\r\n",
        "\r\n",
        "        # block 1\r\n",
        "        x = self.conv1a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv1b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.down1(x)\r\n",
        "        \r\n",
        "        # block 2\r\n",
        "        x = self.conv2a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv2b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.down2(x)\r\n",
        "        \r\n",
        "        # block 3\r\n",
        "        x = self.conv3a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv3b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.down3(x)\r\n",
        "        \r\n",
        "        # block 4\r\n",
        "        x = self.conv4a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv4b(x)\r\n",
        "        x = self.down4(x)\r\n",
        "        \r\n",
        "        # block 5\r\n",
        "        x = self.conv5a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv5b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.down5(x)\r\n",
        "        \r\n",
        "        # block 6\r\n",
        "        x = self.conv6a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv6b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.up1(x)\r\n",
        "        \r\n",
        "        # block 7\r\n",
        "        x = self.conv7a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv7b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.up2(x)\r\n",
        "\r\n",
        "        # block 8\r\n",
        "        x = self.conv8a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv8b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.up3(x)\r\n",
        "        \r\n",
        "        # block 9\r\n",
        "        x = self.conv9a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv9b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.up4(x)\r\n",
        "        \r\n",
        "        # block 10\r\n",
        "        x = self.conv10a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv10b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.up5(x)\r\n",
        "        \r\n",
        "        # block 11\r\n",
        "        x = self.conv11a(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.conv11b(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        scores = self.conv11c(x)\r\n",
        "\r\n",
        "        return scores"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4BJ7XmjwSIK"
      },
      "source": [
        "def train(net,\r\n",
        "          dataloader,\r\n",
        "          n_epoch,\r\n",
        "          optimizer,\r\n",
        "          learning_rate_decay,\r\n",
        "          learning_rate_decay_period):\r\n",
        "    '''\r\n",
        "    Trains the network using a learning rate scheduler\r\n",
        "\r\n",
        "    Args:\r\n",
        "        net : torch.nn.Module\r\n",
        "            neural network\r\n",
        "        dataloader : torch.utils.data.DataLoader\r\n",
        "            # https://pytorch.org/docs/stable/data.html\r\n",
        "            dataloader for training data\r\n",
        "        n_epoch : int\r\n",
        "            number of epochs to train\r\n",
        "        optimizer : torch.optim\r\n",
        "            https://pytorch.org/docs/stable/optim.html\r\n",
        "            optimizer to use for updating weights\r\n",
        "        learning_rate_decay : float\r\n",
        "            rate of learning rate decay\r\n",
        "        learning_rate_decay_period : int\r\n",
        "            period to reduce learning rate based on decay e.g. every 2 epoch\r\n",
        "\r\n",
        "        Please add any necessary arguments\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        torch.nn.Module : trained network\r\n",
        "    '''\r\n",
        "\r\n",
        "    # TODO: Define loss function\r\n",
        "    loss_func = torch.nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "    for epoch in range(n_epoch):\r\n",
        "\r\n",
        "        # Accumulate total loss for each epoch\r\n",
        "        total_loss = 0.0\r\n",
        "\r\n",
        "        # TODO: Decrease learning rate when learning rate decay period is met\r\n",
        "        # e.g. decrease learning rate by a factor of decay rate every 2 epoch\r\n",
        "        if epoch and epoch % learning_rate_decay_period == 0:\r\n",
        "\r\n",
        "          for param_group in optimizer.param_groups:\r\n",
        "            param_group['lr'] = learning_rate_decay * paramgroup['lr']\r\n",
        "\r\n",
        "        for batch, (images, segmentations) in enumerate(dataloader):\r\n",
        "\r\n",
        "          # TODO: Forward through the network\r\n",
        "          outputs = net(images)\r\n",
        "\r\n",
        "          # TODO: Clear gradients so we don't accumlate them from previous batches\r\n",
        "          optimizer.zero_grad()\r\n",
        "\r\n",
        "          # TODO: Compute loss function\r\n",
        "          loss = loss_func(outputs, segmentations)\r\n",
        "\r\n",
        "          # TODO: Update parameters by backpropagation\r\n",
        "          loss.backward()\r\n",
        "          optimizer.step()\r\n",
        "\r\n",
        "          # TODO: Accumulate total loss for the epoch\r\n",
        "          total_loss = total_loss + loss.item()\r\n",
        "\r\n",
        "        mean_loss = total_loss / float(batch)\r\n",
        "\r\n",
        "        # Log average loss over the epoch\r\n",
        "        print('Epoch=%d  Loss: %.3f' % (epoch + 1, mean_loss))\r\n",
        "\r\n",
        "    return net"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3-C6LG4wXTP"
      },
      "source": [
        "def evaluate(net, dataloader):\r\n",
        "    '''\r\n",
        "    Evaluates the network on a dataset\r\n",
        "\r\n",
        "    Args:\r\n",
        "        net : torch.nn.Module\r\n",
        "            neural network\r\n",
        "        dataloader : torch.utils.data.DataLoader\r\n",
        "            # https://pytorch.org/docs/stable/data.html\r\n",
        "            dataloader for training data\r\n",
        "\r\n",
        "        Please add any necessary arguments\r\n",
        "    '''\r\n",
        "    IOU = []\r\n",
        "\r\n",
        "    # Make sure we do not backpropagate\r\n",
        "    with torch.no_grad():\r\n",
        "\r\n",
        "        for (images, segmentations) in dataloader:\r\n",
        "\r\n",
        "            # TODO: Forward through the network\r\n",
        "\r\n",
        "            outputs = net(images)\r\n",
        "\r\n",
        "            # Take the argmax over the outputs\r\n",
        "            _, predictions = torch.max(outputs, dim=1)\r\n",
        "\r\n",
        "            # TODO: Compute evaluation metric(s) for each sample (IOU)\r\n",
        "            #outputs = net(images)\r\n",
        "            iou = intersection_over_union(predictions, segmentations)\r\n",
        "            IOU.append(iou)\r\n",
        "\r\n",
        "    # TODO: Compute mean evaluation metric(s)\r\n",
        "    mean_iou = sum(IOU) / len(IOU)\r\n",
        "\r\n",
        "    # TODO: Print scores\r\n",
        "    print('Mean accuracy: %d' % mean_iou)\r\n",
        "\r\n",
        "    # TODO: Convert the last batch of images back to original shape\r\n",
        "    images = images.view(shape[0], shape[1], shape[2], shape[3])\r\n",
        "    images = images.cpu().numpy()\r\n",
        "    images = np.transpose(images, (0, 2, 3, 1))\r\n",
        "\r\n",
        "    # TODO: Convert the last batch of predictions to the original image shape\r\n",
        "\r\n",
        "    # TODO: Plot images\r\n",
        "    plot_images(images, 5, 5, '...')\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSDCoAWXwYJm"
      },
      "source": [
        "def intersection_over_union(prediction, ground_truth):\r\n",
        "    '''\r\n",
        "    Computes the intersection over union (IOU) between prediction and ground truth\r\n",
        "\r\n",
        "    Args:\r\n",
        "        prediction : numpy\r\n",
        "            N x h x w prediction\r\n",
        "        ground_truth : numpy\r\n",
        "            N x h x w ground truth\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        float : intersection over union\r\n",
        "    '''\r\n",
        "\r\n",
        "    # TODO: Computes intersection over union score\r\n",
        "    # Implement ONLY if you are working on semantic segmentation\r\n",
        "\r\n",
        "    # Flatten the prediction and ground_truth\r\n",
        "    p = torch.flatten(prediction)\r\n",
        "    gt = torch.flatten(ground_truth)\r\n",
        "\r\n",
        "    # call sklearn.metrics.jaccard_score to get IoU\r\n",
        "    return sklearn.metrics.jaccard_score(p, gt)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6lfSXtmwa0e"
      },
      "source": [
        "def mean_squared_error(prediction, ground_truth):\r\n",
        "    '''\r\n",
        "    Computes the mean squared error (MSE) between prediction and ground truth\r\n",
        "\r\n",
        "    Args:\r\n",
        "        prediction : numpy\r\n",
        "            N x h x w prediction\r\n",
        "        ground_truth : numpy\r\n",
        "            N x h x w ground truth\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        float : mean squared error\r\n",
        "    '''\r\n",
        "\r\n",
        "    # TODO: Computes mean squared error\r\n",
        "    # Implement ONLY if you are working on image reconstruction or denoising\r\n",
        "\r\n",
        "    return 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFhwpYSbwjEm"
      },
      "source": [
        "def plot_images(X, Y, n_row, n_col, fig_title):\r\n",
        "    '''\r\n",
        "    Creates n_row by n_col panel of images\r\n",
        "\r\n",
        "    Args:\r\n",
        "        X : numpy\r\n",
        "            N x h x w input data\r\n",
        "        Y : numpy\r\n",
        "            N x h x w predictions\r\n",
        "        n_row : int\r\n",
        "            number of rows in figure\r\n",
        "        n_col : list[str]\r\n",
        "            number of columns in figure\r\n",
        "        fig_title : str\r\n",
        "            title of plot\r\n",
        "\r\n",
        "        Please add any necessary arguments\r\n",
        "    '''\r\n",
        "\r\n",
        "    fig = plt.figure()\r\n",
        "    fig.suptitle(fig_title)\r\n",
        "\r\n",
        "    # TODO: Visualize your input images and predictions\r\n",
        "    for i in range(1, n_row * n_col + 1):\r\n",
        "      ax = fig.add_subplot(n_row, n_col, i)\r\n",
        "      index = i - 1\r\n",
        "      x_i = X[index, ...]\r\n",
        "      subplot_title_i = subplot_title[index]\r\n",
        "      if len(x_i.shape) == 1:\r\n",
        "        x_i = np.expand_dims(x_i, axis=0)\r\n",
        "      ax.set_title(subplot_title_i)\r\n",
        "      ax.imshow(x_i)\r\n",
        "\r\n",
        "      plt.box(False)\r\n",
        "      plt.axis('off')\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFw4qqqreFsa",
        "outputId": "13399ef7-8fa8-4e64-efea-f5fe9c03aa10"
      },
      "source": [
        "# TODO: Set up data preprocessing step\r\n",
        "# https://pytorch.org/docs/stable/torchvision/transforms.html\r\n",
        "data_preprocess_transform = torchvision.transforms.Compose([\r\n",
        "    torchvision.transforms.Resize(size=(256, 256)),\r\n",
        "    torchvision.transforms.ToTensor()\r\n",
        "])\r\n",
        "\r\n",
        "# Download and setup your training set\r\n",
        "dataset_train = torchvision.datasets.VOCSegmentation(\r\n",
        "    root='/content/gdrive/MyDrive/ELEC535final',\r\n",
        "    image_set='train',\r\n",
        "    download=True,\r\n",
        "    transform=data_preprocess_transform,\r\n",
        "    target_transform = data_preprocess_transform\r\n",
        "  )\r\n",
        "\r\n",
        "# Setup a dataloader (iterator) to fetch from the training set\r\n",
        "dataloader_train = torch.utils.data.DataLoader(\r\n",
        "    dataset_train,\r\n",
        "    batch_size=8,\r\n",
        "    shuffle=True,\r\n",
        "    num_workers=0\r\n",
        ")\r\n",
        "\r\n",
        "# Download and setup your validation/testing set\r\n",
        "dataset_val = torchvision.datasets.VOCSegmentation(\r\n",
        "    root='/content/gdrive/MyDrive/ELEC535final',\r\n",
        "    image_set='val',\r\n",
        "    download=True,\r\n",
        "    transform=data_preprocess_transform,\r\n",
        "    target_transform = data_preprocess_transform\r\n",
        ")\r\n",
        "\r\n",
        "# TODO: Setup a dataloader (iterator) to fetch from the validation/testing set\r\n",
        "dataloader_val = torch.utils.data.DataLoader(\r\n",
        "    dataset_val,\r\n",
        "    batch_size=8,\r\n",
        "    shuffle=True,\r\n",
        "    num_workers=0\r\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /content/gdrive/MyDrive/ELEC535final/VOCtrainval_11-May-2012.tar\n",
            "Using downloaded and verified file: /content/gdrive/MyDrive/ELEC535final/VOCtrainval_11-May-2012.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGqyTHrXehQ1"
      },
      "source": [
        "# TODO: Define network\r\n",
        "net = FullyConvolutionalNetwork()\r\n",
        "\r\n",
        "# TODO: Setup learning rate optimizer\r\n",
        "# https://pytorch.org/docs/stable/optim.html?#torch.optim.SGD\r\n",
        "optimizer = torch.optim.SGD(\r\n",
        "    net.parameters(),\r\n",
        "    lr = learning_rate,\r\n",
        "    weight_decay = lambda_weight_decay,\r\n",
        "    momentum=momentum\r\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "sYbCYsTeevkE",
        "outputId": "062205e6-9829-4571-e4de-137c029f46e7"
      },
      "source": [
        "if train_network:\r\n",
        "\r\n",
        "  # Set network to training mode\r\n",
        "  net.train()\r\n",
        "\r\n",
        "  # TODO: Train network and save into checkpoint\r\n",
        "  net = train(\r\n",
        "      net = net,\r\n",
        "      dataloader = dataloader_train,\r\n",
        "      optimizer = optimizer,\r\n",
        "      learning_rate_decay = learning_rate_decay,\r\n",
        "      learning_rate_decay_period = learning_rate_decay_period,\r\n",
        "      n_epoch = n_epoch\r\n",
        "  )\r\n",
        "\r\n",
        "  torch.save({'state_dict' : net.state_dict()}, '/content/drive/My Drive/ELEC535final/checkpoint.pth')\r\n",
        "\r\n",
        "else:\r\n",
        "  # Load network from checkpoint\r\n",
        "  checkpoint = torch.load('/content/drive/My Drive/ELEC535final/checkpoint.pth')\r\n",
        "  net.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-595d2b4a687e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mlearning_rate_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mlearning_rate_decay_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate_decay_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-4cb1e40197eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, dataloader, n_epoch, optimizer, learning_rate_decay, learning_rate_decay_period)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0;31m# TODO: Compute loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmentations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;31m# TODO: Update parameters by backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;31m# dim == 3 or dim > 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr40sQDwfFxR"
      },
      "source": [
        "# Set network to evaluation mode\r\n",
        "net.eval()\r\n",
        "\r\n",
        "# TODO: Evaluate network on testing set\r\n",
        "evaluate(\r\n",
        "    net = net,\r\n",
        "    dataloader = dataloader_test\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "4b66868f590f415daa066e0db979f6bc",
            "7675a9eda3b749bea9e3271fc6ac86cd",
            "aedd46dd73f24c0c8423880030a15fc0",
            "724ac8e851174860998e01dd68cc1ac0",
            "2b3eecc5b3ef4997a9d37cb2beda4016",
            "67e9295208df4876b1bd8780074f1cb3",
            "736fb9519bb94bcc9b465c58ea946c5c",
            "ba446ed6c847429bb7199b11b50ce411"
          ]
        },
        "id": "P-3JhihOwmYv",
        "outputId": "ec62352d-3498-4121-8aba-e720fde0ee72"
      },
      "source": [
        "'''if __name__ == '__main__':\r\n",
        "\r\n",
        "    # TODO: Set up data preprocessing step\r\n",
        "    # https://pytorch.org/docs/stable/torchvision/transforms.html\r\n",
        "    data_preprocess_transform = torchvision.transforms.Compose([\r\n",
        "        torchvision.transforms.Resize(size=(256, 256)),\r\n",
        "        torchvision.transforms.ToTensor()\r\n",
        "    ])\r\n",
        "\r\n",
        "    # Download and setup your training set\r\n",
        "    dataset_train = torchvision.datasets.VOCSegmentation(\r\n",
        "        root='/content/gdrive/MyDrive/ELEC535final',\r\n",
        "        image_set='train',\r\n",
        "        download=True,\r\n",
        "        transform=data_preprocess_transform,\r\n",
        "        target_transform = data_preprocess_transform\r\n",
        "    )\r\n",
        "\r\n",
        "    # Setup a dataloader (iterator) to fetch from the training set\r\n",
        "    dataloader_train = torch.utils.data.DataLoader(\r\n",
        "        dataset_train,\r\n",
        "        batch_size=8,\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=0\r\n",
        "    )\r\n",
        "\r\n",
        "    # Download and setup your validation/testing set\r\n",
        "    dataset_val = torchvision.datasets.VOCSegmentation(\r\n",
        "        root='./data',\r\n",
        "        image_set='val',\r\n",
        "        download=True,\r\n",
        "        transform=data_preprocess_transform,\r\n",
        "        target_transform = data_preprocess_transform\r\n",
        "    )\r\n",
        "\r\n",
        "    # TODO: Setup a dataloader (iterator) to fetch from the validation/testing set\r\n",
        "    dataloader_val = torch.utils.data.DataLoader(\r\n",
        "        dataset_val,\r\n",
        "        batch_size=8,\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=0\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    # TODO: Define network\r\n",
        "    net = FullyConvolutionalNetwork()\r\n",
        "\r\n",
        "    # TODO: Setup learning rate optimizer\r\n",
        "    # https://pytorch.org/docs/stable/optim.html?#torch.optim.SGD\r\n",
        "    optimizer = torch.optim.SGD(\r\n",
        "        net.parameters(),\r\n",
        "        lr = learning_rate,\r\n",
        "        weight_decay = lambda_weight_decay,\r\n",
        "        momentum=momentum\r\n",
        "    )\r\n",
        "\r\n",
        "    if train_network:\r\n",
        "        # Set network to training mode\r\n",
        "        net.train()\r\n",
        "\r\n",
        "        # TODO: Train network and save into checkpoint\r\n",
        "        net = train(\r\n",
        "            net = net,\r\n",
        "            dataloader = dataloader_train,\r\n",
        "            optimizer = optimizer,\r\n",
        "            learning_rate_decay = learning_rate_decay,\r\n",
        "            learning_rate_decay_period = learning_rate_decay_period\r\n",
        "        )\r\n",
        "\r\n",
        "        torch.save({'state_dict' : net.state_dict()}, '/content/drive/My Drive/ELEC535final/checkpoint.pth')\r\n",
        "\r\n",
        "    else:\r\n",
        "        # Load network from checkpoint\r\n",
        "        checkpoint = torch.load('/content/drive/My Drive/ELEC535final/checkpoint.pth')\r\n",
        "        net.load_state_dict(checkpoint['state_dict'])\r\n",
        "\r\n",
        "    # Set network to evaluation mode\r\n",
        "    net.eval()\r\n",
        "\r\n",
        "    # TODO: Evaluate network on testing set\r\n",
        "    evaluate(\r\n",
        "        net = net,\r\n",
        "        dataloader = dataloader_test\r\n",
        "    )'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to /content/gdrive/MyDrive/ELEC535final/VOCtrainval_11-May-2012.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b66868f590f415daa066e0db979f6bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c54f54ecff69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# https://pytorch.org/docs/stable/optim.html?#torch.optim.SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     optimizer = torch.optim.SGD(\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_weight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'FullyConvolutionalNetwork' object has no attribute 'parameter'"
          ]
        }
      ]
    }
  ]
}